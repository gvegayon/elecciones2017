---
title: Elecciones Chile 2017
output: github_document
---

En este sitio web encontrarás visualizaciones del contenido de las cuentas de twitter de los candidatos presidenciales en Chile 2017 __como redes sociales__. Tanto la descarga de los datos como la creacion de este sitio web fue realizada con el lenguaje de programación R junto con los paquetes [rgexf](https://github.com/gvegayon/rgexf) y [twitterreport](https://github.com/gvegayon/twitterreport), ambos de los cuales [soy el autor](http://ggvy.cl). Este sitio web ha sido desarrollado para ilustrar el uso de estos paquetes de R (ver código [aquí](https://github.com/gvegayon/elecciones2017)).

Por el momento sólo tengo dos tipos de "análisis" (pues solo son visualizaciones de datos sin explicación :)):

1.  Redes semánticas de los tweets de los candidatos (cómo se relacionan las palabras que incluyen en sus tweets). Estas redes incluyen los últimos 1.000 tweets de cada candidato.

2.  Listado de palabras asociadas con cada candidato. Descargando los últimos 50.000 tweets que mencionan a cualquiera de los candidatos, construí el listado de conceptos que, en términos relativos, aparecen con mayor frecuencia con cada uno de ellos.

Ambos "análisis" utilizan el [Índice de Jaccard](https://es.wikipedia.org/wiki/%C3%8Dndice_Jaccard).

Este es un proyecto hermano de https://elecciones2017.github.io/

# De qué hablan los candidatos de #EleccionesChile2017?

A continuación un listado de links a visualizaciones de las redes semánticas (?) de cada candidato. Si dos palabras aparecen conectadas significa que aparecen juntas de manera frecuente.

```{r, echo=FALSE}
candidatos <- c("carolinagoic", "eduardo_artes", "joseantoniokast", "BeaSanchezYTu",
                "sebastianpinera", "guillier", "marcoporchile", "senadornavarro")
```

```{r, results='asis', echo=FALSE}
for (can in candidatos)
  cat("<p>Red de <a href=\"",can,"/index.html\">",can,"</a></p>\n", sep="")
```
<br>

```{r, results='asis', echo=FALSE}
cat(readLines("tweets/candidatos.md", warn = FALSE)[-c(1:3)])
```

# Qué se habla sobre los candidatos?

A continuación, una tabla con los las palabras que aparecen con mayor frecuencia junto a menciones a los candidatos. La tabla fue creada en base a la descarga de 50.000 tweets bajo el criterio de que fueran emitidos en español, y mencionaran al menos a uno de los candidatos.

```{r sobre-candidatos, echo=FALSE}
load("tweets/sobre_candidatos.rda")

# No necesito el score, solo el termino
sobre_candidatos <- lapply(sobre_candidatos, "[[", "word")

nartes <- length(sobre_candidatos$eduardo_artes)
sobre_candidatos$eduardo_artes <- c(sobre_candidatos$eduardo_artes, rep("-", 20-nartes))

tab <- do.call(cbind, sobre_candidatos)
tab <- tab[-1,]
dimnames(tab) <- list(1:nrow(tab),names(sobre_candidatos))

knitr::kable(tab, row.names = TRUE)
```

```{r, results='asis', echo=FALSE}
cat(readLines("tweets/sobre_candidatos.md", warn = FALSE)[-c(1:3)])
```


# Metodología

En términos sencillos, dependiendo del tipo de "análisis", lo que hice para generar los datos fue lo siguiente:

1.  Descargar tweets usando la API de twitter a través del paquete twitterreport.

2.  De cada tweet, eliminar los stopwords y luego calcular el [Índice de Jaccard](https://es.wikipedia.org/wiki/%C3%8Dndice_Jaccard) utilizando todos los tweets disponibles del candidato

3.  En el caso de las redes, dicotomizar la matriz resultante del paso anterior dejando como 1 si la celda es mayor a la mediana, de lo contrario queda como 0.

4.  Filtrar los 100 términos más populares de la lista (según la diagonal de la matriz de similitud)

5.  Con esa matriz, una matriz adjacente ahora, identificar clusters (para eso utilicé igraph, en particular, el algoritmo Fast Greedy) y etiquetar (colorear) las palabras según comunidad

6.  Generar un layout y exportar utilizando el paquete rgexf.


# Contacto

George G. Vega Yon

[\@gvegayon](https://twitter.com/gvegayon)

http://ggvy.cl